<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<meta http-equiv="content-type" content="text/html"; charset="utf-8" />
	<meta name="author" content="Christian Schulte" />
	<link rel="stylesheet" type="text/css" 
              href="https://chschulte.github.io/style.css" title="1024px" media="screen,projection" />
	<title>Christian Schulte: Papers</title>
</head>

<body>
<div id="wrap">
  <div id="header">
    <p id="toplinks">[<a href="#content">content</a> | 
<a href="#sidebar">navigation</a> |                      <a href="#footer">footer</a>]
    </p>
    <h1>Papers</h1>
    <p id="slogan">Christian Schulte</p>
  </div>
<div id="sidebar"><h2>information</h2><ul><li><a href="https://chschulte.github.io/index.html">main</a></li><li><a href="https://chschulte.github.io/contact.html">contact</a></li><li><a href="https://chschulte.github.io/papers.html">papers</a></li><li><a href="https://chschulte.github.io/software.html">software</a></li><li><a href="https://chschulte.github.io/education.html">education</a></li><li><a href="https://chschulte.github.io/presentations.html">presentations</a></li><li><a href="https://chschulte.github.io/bio.html">short bio</a></li></ul><h2>options</h2><ul>
<li><a href="papers.html">selected</a></li>
<li><a href="papers-year.html">by year</a></li>
<li><a href="papers-type.html">by type</a></li>
</ul></div>
<div id="content">

  <h2>Confidence based Work Stealing</h2>

  <p>Geoffrey Chu, <a href="https://chschulte.github.io/">Christian Schulte</a>, <a href="http://www.cs.mu.oz.au/~pjs/">Peter J. Stuckey</a>.</p>

  <p>
  [<a href="papers/chuschultestuckey-ciclops-2008.pdf">pdf</a> | <a href="bibtex-chuschultestuckey-ciclops-2008.html">bibtex</a>]
  </p>

  <p>    
  In parallel constraint solving, work stealing not only allows for dynamic
  load balancing, but also determines which parts of the search tree are
  searched next. Thus the place from where work is stolen has a dramatic effect
  on the efficiency of a parallel search algorithm. In this paper we examine
  quantitatively how optimal work stealing can be performed given an
  estimate of the relative solution densities of the subtrees at each node in the search
  tree and show how this is related to the branching heuristic strength. We propose an adaptive work stealing algorithm that automatically
  performs different work stealing strategies based on the strength of the
  branching heuristic at each node. Search patterns such as parallel versions of DFS, IDFS, LDS, DDS and many others arise naturally from our algorithm. Our algorithm is able to produce near perfect or
  super linear algorithmic efficiencies on all problems tested. Real
  speedups using 8 threads ranged from 4-5 times speedup to super linear
  speedup.
</p>
  <p>
  <b>In:</b> Manuel Carro, Bart Demoen, editors, <i>Proceedings of the Eigth International Colloquium on Implementation of Constraint and Logic Programming Systems</i>, <i>Udine, Italy</i>. December, 2008.   </p>

</div>


  <div id="footer">
    &copy; 2009 <a href="https://chschulte.github.io/">Christian Schulte</a> (Fri Feb 2 14:14:23 2018) |
    original design by <a href="http://andreasviklund.com/"
    >Andreas Viklund</a>
  </div>

</div>
</body>
</html>
